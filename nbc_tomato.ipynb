{
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    },
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": "import csv\nimport random\nimport math",
      "metadata": {
        "trusted": true
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "# creating the function to load the dataset.\ndef LoadDataset(filename):\n    dataset = []\n    with open(filename, 'r') as csvfile:\n        reader = csv.reader(csvfile)\n        for row in reader:\n            dataset.append(row)\n    return dataset",
      "metadata": {
        "trusted": true
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "\n# then split the dataset into train, dev, and test sets\ndef split_train_dev_eval(dataset, split_ratio):\n    train_size = int(len(dataset) * split_ratio) # split the train according to input ratio\n    train_dataset = []\n    devandeval = dataset[:]\n    while len(train_dataset) < train_size:\n        index = random.randrange(len(devandeval))\n        train_dataset.append(devandeval.pop(index))\n    return [train_dataset, devandeval, devandeval] #return list contains the three parts.",
      "metadata": {
        "trusted": true
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "# function that calculates the word occurence in all reviews\ndef word_occurrences(dataset, vocabulary):\n    WordOccurrences = {}\n    for word in vocabulary:\n        WordOccurrences[word] = 0\n        for document in dataset:\n            if word in document[0].split():\n                WordOccurrences[word] += 1\n    return WordOccurrences",
      "metadata": {
        "trusted": true
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "\n# function that calculates the probability of each class (fresh or rotten)\ndef ClassProbabilities(dataset):\n\n    class_probabilities = {}\n    \n    for document in dataset:\n        sentiment = document[0]\n        if sentiment == \"Freshness\": # ignoring the excess lables from the dataset.\n            pass\n        else:\n\n            if sentiment not in class_probabilities:\n                class_probabilities[sentiment] = 1 \n            else:\n                class_probabilities[sentiment] += 1 #counting the number of reviews by adding ones in each loop trun.\n    total_documents = len(dataset) #the number of all reviews\n    \n    for sentiment in class_probabilities:\n        class_probabilities[sentiment] /= total_documents\n        \n        \n    return class_probabilities #returns dictionary of both classes probabilities.",
      "metadata": {
        "trusted": true
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "# calculating the conditional probability of each word given the class.\ndef word_conditional_probability(dataset, vocabulary, word_occurrences):\n    conditional_probabilities = {}\n    total_words_per_class = {}\n    for sentiment in [\"fresh\",\"rotten\"]:\n        total_words_per_class[sentiment] = 0\n        for word in vocabulary:\n            total_words_per_class[sentiment] += word_occurrences[word][sentiment] + 1\n    for word in vocabulary:\n        conditional_probabilities[word] = {}\n        for sentiment in [\"fresh\",\"rotten\"]:\n            conditional_probabilities[word][sentiment] = (word_occurrences[word][sentiment] + 1) / total_words_per_class[sentiment]\n    return conditional_probabilities #returns dictionary of each word and its corrseponding probability in both classes.",
      "metadata": {
        "trusted": true
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "# here we make predictions according to the model we created.\ndef predict(document, vocabulary, class_probabilities, conditional_probabilities):\n    words = document.split()\n    positive_probability = math.log(class_probabilities['fresh'])\n    negative_probability = math.log(class_probabilities['rotten'])\n    for word in words:\n        if word in vocabulary:\n            positive_probability += math.log(conditional_probabilities[word]['fresh'])\n            negative_probability += math.log(conditional_probabilities[word]['rotten'])\n    if positive_probability > negative_probability:\n        return 'fresh'\n    else:\n        return 'rotten'\n   ",
      "metadata": {
        "trusted": true
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "# then lets evaluate our model.\ndef evaluate(dataset, vocabulary, class_probabilities, conditional_probabilities):\n    correct_predictions = 0\n    for document in dataset:\n        predicted_sentiment = predict(document[1], vocabulary, class_probabilities, conditional_probabilities)\n        if predicted_sentiment == document[0]:\n            correct_predictions += 1\n    accuracy = correct_predictions / len(dataset)\n    return accuracy",
      "metadata": {
        "trusted": true
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "# the main function\ndef main():\n    \n    #loading the dataset\n    dataset = LoadDataset('rt_reviews.csv')\n\n    # Split the dataset into train, dev, and test sets\n    train_set, dev_set, test_set = split_train_dev_eval(dataset, 0.6)\n    \n    vocab_list = [\"good\",\"bad\",\"enjoyable\",\"fresh\",\"clean\",\"fun\",\"dark\",\"black\",\"harsh\",\"low\"] #pick the top 10 perfect word for the model.\n    \n    #calculatingthe word occurrence\n    \n    word_occurrences = {}\n    for word in vocab_list: #     positive     neg1tive\n        word_occurrences[word] = {'fresh': 0, 'rotten': 0}\n        for document in train_set:\n            if word in document[1].split():\n                sentiment = document[0]\n                if sentiment==\"Freshness\":\n                    pass\n                else:\n                    word_occurrences[word][sentiment] += 1\n    # lets do the calculations\n    # Calculate ClassProbabilities\n    class_probabilities = ClassProbabilities(train_set)\n    print(\"Class Probabilities:\",class_probabilities) # prior probability.\n    \n    conditional_probabilities = word_conditional_probability(train_set, vocab_list, word_occurrences)\n    print(\"Conditional Probabilities:\")\n    for word in conditional_probabilities: print(word,\":\",conditional_probabilities[word])\n    # Evaluate the accuracy of the classifier on the development set\n    dev_accuracy = evaluate(dev_set, vocab_list, class_probabilities, conditional_probabilities)\n    print(\"Accuracy:\",dev_accuracy)\n    ",
      "metadata": {
        "trusted": true
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "# run the code\nmain()\n",
      "metadata": {
        "trusted": true
      },
      "execution_count": 31,
      "outputs": [
        {
          "name": "stdout",
          "text": "Class Probabilities: {'rotten': 0.4997986111111111, 'fresh': 0.5002013888888889}\nConditional Probabilities:\ngood : {'fresh': 0.3951655746414025, 'rotten': 0.3909152806147262}\nbad : {'fresh': 0.06959447494244732, 'rotten': 0.28149012741951174}\nenjoyable : {'fresh': 0.0918186647777581, 'rotten': 0.02431670071004766}\nfresh : {'fresh': 0.05994333274304941, 'rotten': 0.03161171092306196}\nclean : {'fresh': 0.0060208960510005315, 'rotten': 0.007975877832895632}\nfun : {'fresh': 0.21524703382326899, 'rotten': 0.131115650228577}\ndark : {'fresh': 0.08402691694705153, 'rotten': 0.04970333625133742}\nblack : {'fresh': 0.049672392420754385, 'rotten': 0.039198521544596826}\nharsh : {'fresh': 0.011156366212148043, 'rotten': 0.0035016049022468633}\nlow : {'fresh': 0.01735434744111918, 'rotten': 0.040171189572998735}\nAccuracy: 0.507460898641153\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": "",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    }
  ]
}