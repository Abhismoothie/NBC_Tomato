{
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    },
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": "import csv\nimport random\nimport math",
      "metadata": {
        "trusted": true
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "# creating the function to load the dataset.\ndef LoadDataset(filename):\n    dataset = []\n    with open(filename, 'r') as csvfile:\n        reader = csv.reader(csvfile)\n        for row in reader:\n            dataset.append(row)\n    return dataset",
      "metadata": {
        "trusted": true
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "\n# then split the dataset into train, dev, and test sets\ndef split_train_dev_eval(dataset, split_ratio):\n    train_size = int(len(dataset) * split_ratio) # split the train according to input ratio\n    train_dataset = []\n    devandeval = dataset[:]\n    while len(train_dataset) < train_size:\n        index = random.randrange(len(devandeval))\n        train_dataset.append(devandeval.pop(index))\n    return [train_dataset, devandeval, devandeval] #return list contains the three parts.",
      "metadata": {
        "trusted": true
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "# function that calculates the word occurence in all reviews\ndef word_occurrences(dataset, vocabulary):\n    WordOccurrences = {}\n    for word in vocabulary:\n        WordOccurrences[word] = 0\n        for document in dataset:\n            if word in document[0].split():\n                WordOccurrences[word] += 1\n    return WordOccurrences",
      "metadata": {
        "trusted": true
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "\n# function that calculates the probability of each class (fresh or rotten)\ndef ClassProbabilities(dataset):\n\n    class_probabilities = {}\n    \n    for document in dataset:\n        sentiment = document[0]\n        if sentiment == \"Freshness\": # ignoring the excess lables from the dataset.\n            pass\n        else:\n\n            if sentiment not in class_probabilities:\n                class_probabilities[sentiment] = 1 \n            else:\n                class_probabilities[sentiment] += 1 #counting the number of reviews by adding ones in each loop trun.\n    total_documents = len(dataset) #the number of all reviews\n    \n    for sentiment in class_probabilities:\n        class_probabilities[sentiment] /= total_documents\n        \n        \n    return class_probabilities #returns dictionary of both classes probabilities.",
      "metadata": {
        "trusted": true
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "# calculating the conditional probability of each word given the class.\ndef word_conditional_probability(dataset, vocabulary, word_occurrences):\n    conditional_probabilities = {}\n    total_words_per_class = {}\n    for sentiment in [\"fresh\",\"rotten\"]:\n        total_words_per_class[sentiment] = 0\n        for word in vocabulary:\n            total_words_per_class[sentiment] += word_occurrences[word][sentiment] + 1\n    for word in vocabulary:\n        conditional_probabilities[word] = {}\n        for sentiment in [\"fresh\",\"rotten\"]:\n            conditional_probabilities[word][sentiment] = (word_occurrences[word][sentiment] + 1) / total_words_per_class[sentiment]\n    return conditional_probabilities #returns dictionary of each word and its corrseponding probability in both classes.",
      "metadata": {
        "trusted": true
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "# here we make predictions according to the model we created.\ndef predict(document, vocabulary, class_probabilities, conditional_probabilities):\n    words = document.split()\n    positive_probability = math.log(class_probabilities['fresh'])\n    negative_probability = math.log(class_probabilities['rotten'])\n    for word in words:\n        if word in vocabulary:\n            positive_probability += math.log(conditional_probabilities[word]['fresh'])\n            negative_probability += math.log(conditional_probabilities[word]['rotten'])\n    if positive_probability > negative_probability:\n        return 'fresh'\n    else:\n        return 'rotten'\n   ",
      "metadata": {
        "trusted": true
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "# then lets evaluate our model.\ndef evaluate(dataset, vocabulary, class_probabilities, conditional_probabilities):\n    correct_predictions = 0\n    for document in dataset:\n        predicted_sentiment = predict_sentiment(document[1], vocabulary, class_probabilities, conditional_probabilities)\n        if predicted_sentiment == document[0]:\n            correct_predictions += 1\n    accuracy = correct_predictions / len(dataset)\n    return accuracy",
      "metadata": {
        "trusted": true
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "# the main function\ndef main():\n    \n    #loading the dataset\n    dataset = LoadDataset('rt_reviews.csv')\n\n    # Split the dataset into train, dev, and test sets\n    train_set, dev_set, test_set = split_train_dev_eval(dataset, 0.6)\n    \n    vocab_list = [\"good\",\"bad\",\"enjoyable\",\"fresh\",\"clean\",\"fun\",\"dark\",\"black\",\"harsh\",\"low\"] #pick the top 10 perfect word for the model.\n    \n    #calculatingthe word occurrence\n    \n    word_occurrences = {}\n    for word in vocabulary: #     positive     neg1tive\n        word_occurrences[word] = {'fresh': 0, 'rotten': 0}\n        for document in train_set:\n            if word in document[1].split():\n                sentiment = document[0]\n                if sentiment==\"Freshness\":\n                    pass\n                else:\n                    word_occurrences[word][sentiment] += 1\n    # lets do the calculations\n    # Calculate ClassProbabilities\n    class_probabilities = ClassProbabilities(train_set)\n    print(\"Class Probabilities:\",class_probabilities) # prior probability.\n    \n    conditional_probabilities = word_conditional_probability(train_set, vocabulary, word_occurrences)\n    print(\"Conditional Probabilities:\",conditional_probabilities)\n    # Evaluate the accuracy of the classifier on the development set\n    dev_accuracy = evaluate(dev_set, vocabulary, class_probabilities, conditional_probabilities)\n    print(\"Accuracy:\",dev_accuracy)\n    ",
      "metadata": {
        "trusted": true
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "# run the code\nmain()\n",
      "metadata": {
        "trusted": true
      },
      "execution_count": 19,
      "outputs": [
        {
          "ename": "<class 'FileNotFoundError'>",
          "evalue": "[Errno 44] No such file or directory: 'rt_reviews.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[19], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# run the code\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[0;32mIn[18], line 5\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmain\u001b[39m():\n\u001b[1;32m      3\u001b[0m     \n\u001b[1;32m      4\u001b[0m     \u001b[38;5;66;03m#loading the dataset\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m \u001b[43mLoadDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrt_reviews.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;66;03m# Split the dataset into train, dev, and test sets\u001b[39;00m\n\u001b[1;32m      8\u001b[0m     train_set, dev_set, test_set \u001b[38;5;241m=\u001b[39m split_train_dev_eval(dataset, \u001b[38;5;241m0.6\u001b[39m)\n",
            "Cell \u001b[0;32mIn[3], line 4\u001b[0m, in \u001b[0;36mLoadDataset\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mLoadDataset\u001b[39m(filename):\n\u001b[1;32m      3\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m----> 4\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m csvfile:\n\u001b[1;32m      5\u001b[0m         reader \u001b[38;5;241m=\u001b[39m csv\u001b[38;5;241m.\u001b[39mreader(csvfile)\n\u001b[1;32m      6\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m reader:\n",
            "File \u001b[0;32m/lib/python3.11/site-packages/IPython/core/interactiveshell.py:284\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    279\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    280\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    281\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    282\u001b[0m     )\n\u001b[0;32m--> 284\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 44] No such file or directory: 'rt_reviews.csv'"
          ],
          "output_type": "error"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": "",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    }
  ]
}