{
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    },
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": "import csv\nimport random\nimport math",
      "metadata": {
        "trusted": true
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "# creating the function to load the dataset.\ndef LoadDataset(filename):\n    dataset = []\n    with open(filename, 'r') as csvfile:\n        reader = csv.reader(csvfile)\n        for row in reader:\n            dataset.append(row)\n    return dataset",
      "metadata": {
        "trusted": true
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "\n# then split the dataset into train, dev, and test sets\ndef split_train_dev_eval(dataset, split_ratio):\n    train_size = int(len(dataset) * split_ratio) # split the train according to input ratio\n    train_dataset = []\n    devandeval = dataset[:]\n    while len(train_dataset) < train_size:\n        index = random.randrange(len(devandeval))\n        train_dataset.append(devandeval.pop(index))\n    return [train_dataset, devandeval, devandeval] #return list contains the three parts.",
      "metadata": {
        "trusted": true
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "# function that calculates the word occurence in all reviews\ndef word_occurrences(dataset, vocabulary):\n    WordOccurrences = {}\n    for word in vocabulary:\n        WordOccurrences[word] = 0\n        for document in dataset:\n            if word in document[0].split():\n                WordOccurrences[word] += 1\n    return WordOccurrences",
      "metadata": {
        "trusted": true
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "\n# function that calculates the probability of each class (fresh or rotten)\ndef ClassProbabilities(dataset):\n\n    class_probabilities = {}\n    \n    for document in dataset:\n        sentiment = document[0]\n        if sentiment == \"Freshness\": # ignoring the excess lables from the dataset.\n            pass\n        else:\n\n            if sentiment not in class_probabilities:\n                class_probabilities[sentiment] = 1 \n            else:\n                class_probabilities[sentiment] += 1 #counting the number of reviews by adding ones in each loop trun.\n    total_documents = len(dataset) #the number of all reviews\n    \n    for sentiment in class_probabilities:\n        class_probabilities[sentiment] /= total_documents\n        \n        \n    return class_probabilities #returns dictionary of both classes probabilities.",
      "metadata": {
        "trusted": true
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "# calculating the conditional probability of each word given the class.\ndef word_conditional_probability(dataset, vocabulary, word_occurrences):\n    conditional_probabilities = {}\n    total_words_per_class = {}\n    for sentiment in [\"fresh\",\"rotten\"]:\n        total_words_per_class[sentiment] = 0\n        for word in vocabulary:\n            total_words_per_class[sentiment] += word_occurrences[word][sentiment] + 1\n    for word in vocabulary:\n        conditional_probabilities[word] = {}\n        for sentiment in [\"fresh\",\"rotten\"]:\n            conditional_probabilities[word][sentiment] = (word_occurrences[word][sentiment] + 1) / total_words_per_class[sentiment]\n    return conditional_probabilities #returns dictionary of each word and its corrseponding probability in both classes.",
      "metadata": {
        "trusted": true
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "# here we make predictions according to the model we created.\ndef predict(document, vocabulary, class_probabilities, conditional_probabilities):\n    words = document.split()\n    positive_probability = math.log(class_probabilities['fresh'])\n    negative_probability = math.log(class_probabilities['rotten'])\n    for word in words:\n        if word in vocabulary:\n            positive_probability += math.log(conditional_probabilities[word]['fresh'])\n            negative_probability += math.log(conditional_probabilities[word]['rotten'])\n    if positive_probability > negative_probability:\n        return 'fresh'\n    else:\n        return 'rotten'\n   ",
      "metadata": {
        "trusted": true
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "# then lets evaluate our model.\ndef evaluate_classifier(dataset, vocabulary, class_probabilities, conditional_probabilities):\n    correct_predictions = 0\n    for document in dataset:\n        predicted_sentiment = predict_sentiment(document[1], vocabulary, class_probabilities, conditional_probabilities)\n        if predicted_sentiment == document[0]:\n            correct_predictions += 1\n    accuracy = correct_predictions / len(dataset)\n    return accuracy",
      "metadata": {
        "trusted": true
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    }
  ]
}